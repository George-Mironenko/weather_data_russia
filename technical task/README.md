Техническое задание
На внедрение программного продукта для сбора, хранения, архивации и мониторинга глобальных погодных данных

1. Общие сведения
- Полное наименование ИС (информационной системы):
  «Глобальная система сбора и мониторинга текущих метеорологических данных».

- Шифр темы:
  Times New Roman

- Предприятие-разработчик системы:
  Георгий Мироненко Вячеславович.

- Предприятие-заказчик системы:
  Учебный/личный проект с потенциалом масштабирования для исследовательских, образовательных или коммерческих целей

- Система создается на основании технического задания (ТЗ):
  Настоящего технического задания.

- Плановый срок начала работ:
  1 сентября 2025 г.

- Плановый срок окончания работ:
  24 сентября 2025 г.

- Автоматизируемая система создается на программно-аппаратной основе с использованием современных практик инженерии данных: контейнеризация (Docker), оркестрация (Apache Airflow), реляционное и файловое хранение (PostgreSQL + Parquet/S3), кэширование состояний (Redis), а также интеграция с внешними API и системами уведомлений.

- Порядок оформления и предъявления заказчику результатов работы по созданию системы определяется после получения начальной версии продукта, в которой должны быть реализованы все основные функции, определенные в настоящем ТЗ, включая поддержку многорегиональных данных и базовую систему алертинга.

2. Назначение и цели создания системы

Вид автоматизируемой деятельности:
  Автоматизированный сбор, обработка, хранение, архивация и мониторинг актуальных метеорологических данных по городам всего мира с возможностью детектирования аномальных изменений погоды и отправки уведомлений.

Перечень автоматизируемых процессов:
1.	Ежечасный опрос глобального погодного API OpenWeatherMap для получения данных по тысячам городов.
2.	Парсинг, валидация и нормализация полученных данных.
3.	Запись структурированных наблюдений в реляционную базу данных (PostgreSQL) с поддержкой географической иерархии (страна → регион → город).
4.	Ежемесячная архивация исторических данных в колонковом формате Parquet и выгрузка в S3-совместимое облачное хранилище (например, Selectel, AWS S3).

- Наименование и значение показателей, которые будут достигнуты в результате внедрения Системы:
•	Охват географии: поддержка ≥ 10 00 городов в 200+ странах мира
•	Полнота данных: ≥ 95% успешных запросов к API в течение суток
•	Скорость обработки: полный цикл ETL (от запроса до записи в БД) ≤ 2 минут
•	Задержка алертинга: уведомление о значительном изменении погоды ≤ 5 минут после фиксации
  - Масштабируемость: архитектура позволяет увеличить частоту сбора до 5-минутных интервалов без перепроектирования
  - Надёжность: автоматическое восстановление после сбоев (благодаря Airflow + Docker)
  - Экономия ресурсов: 100% автоматизация рутинных операций — от сбора до архивации

3. Характеристики объекта автоматизации
•	Краткие сведения о предприятии:
•	Проект реализуется в рамках самообразования и демонстрации компетенций в области инженерии данных. Объектом автоматизации является глобальный процесс мониторинга погоды, ранее выполнявшийся вручную или не выполнявшийся вовсе. Системa предназначена для:
•	обучения и отработки навыков проектирования data pipelines,
•	последующего использования в исследовательских задачах (анализ климатических трендов),
•	интеграции в образовательные платформы или сервисы раннего предупреждения о погодных аномалиях.

  Источником данных выступает публичный API OpenWeatherMap, но архитектура допускает подключение дополнительных провайдеров.

4. Требования к ИС

4.1. Требования к системе в целом:
•	Система должна быть полностью контейнеризована (Docker + Docker Compose).
•	Должна поддерживать масштабируемую оркестрацию через Apache Airflow (CeleryExecutor или KubernetesExecutor в будущем).
•	Все данные должны храниться в нормализованной реляционной БД (PostgreSQL) с поддержкой географических справочников.
•	Должна обеспечиваться возможность глобального мониторинга с гибкой настройкой порогов алертинга по регионам.
•	Архитектура должна быть модульной, расширяемой и облачно-нейтральной (работает локально и в облаке).
•	Должна быть реализована политика хранения данных: «горячие» данные — в PostgreSQL, «холодные» — в Parquet/S3.

4.2. Требования к программному обеспечению ИС:
•	Язык программирования: Python 3.12+
•	Библиотеки обработки данных: Polars (основной), с возможностью миграции на PySpark при росте объёмов
•	Оркестратор: Apache Airflow 2.9+
•	СУБД: PostgreSQL 15+ с расширением PostGIS (опционально — для геопространственных запросов)
•	Формат архива: Apache Parquet (сжатие Snappy/Zstandard)
•	Хранилище архивов: S3-совместимый бакет (Selectel, AWS, MinIO и др.)
•	Лицензия: MIT License — разрешает свободное использование, модификацию и распространение, включая коммерческое

4.3. Требования к техническому обеспечению АС:
•	Операционная система: Linux (Ubuntu 22.04 LTS или аналог)
•	Минимальные аппаратные требования:
•	CPU: 2–4 ядра
•	RAM: 6–8 ГБ (из-за Airflow + PostgreSQL + Redis)
•	-Диск: 50 ГБ SSD (с учётом роста данных)
-	Поддержка Docker Engine 24+ и Docker Compose v2+
•	- Стабильное подключение к интернету (для вызова API и отправки уведомлений)
•	- Доступ к S3-совместимому хранилищу (можно использовать локальный MinIO для тестирования)

5. Стадии и этапы разработки

Разработка Системы проводится в три стадии:
1. Разработка технического задания
•	Анализ глобальных источников погодных данных
•	Определение структуры справочников (страны, города, регионы)
•	Формирование требований к масштабируемости и безопасности
•	Утверждение ТЗ

2. Рабочее проектирование
На данной стадии выполняются следующие этапы работ:
•	Проектирование расширенной ER-модели БД (включая страны, регионы, города, условия погоды)
•	Разработка DAG-файлов Airflow:
•	discovery_dag — загрузка/обновление справочника городов
•	ingestion_dag — ежечасный сбор погодных данных по всем городам
•	alerting_dag — сравнение с предыдущими значениями и отправка уведомлений
•	archival_dag — экспорт в Parquet и загрузку в S3
•	Реализация Python-модулей: API-клиент, трансформация данных, логика алертинга
•	Настройка Docker Compose-окружения (Airflow, PostgreSQL, Redis, MinIO/S3 proxy)
•	Интеграция с Telegram Bot API
•	Локальное тестирование полного цикла ETL

3. Внедрение
•	Развертывание системы на целевом сервере (локальном или облачном)
•	Настройка расписания DAG-ов
•	Мониторинг стабильности и производительности
•	Подготовка документации и передача системы

На этапе подготовки и передачи программы должна быть выполнена работа по подготовке и передаче программы и программной документации в эксплуатацию, включая:
•	Исходный код с лицензией MIT
•	docker-compose.yml и .env.example
•	Инструкцию по первоначальной настройке (API-ключи, Telegram-бот, S3-credentials)
•	Схему базы данных (в виде диаграммы и SQL-скрипта)
•	Описание DAG-ов и логики алертинга
Руководство по расширению функционала (добавление новых метрик, источников, каналов уведомлений)
